{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f815ff5",
   "metadata": {},
   "source": [
    "# Week 5 - 주간학습정리 - NLP\n",
    "\n",
    "## 깨달은 내용\n",
    "* 신규용어\n",
    "* subword tokenization의 효용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5323e24a",
   "metadata": {},
   "source": [
    "## 신규 용어\n",
    "* 토큰화 (tokeniztion)\n",
    "    * 주어진 주어진 text를 token이라 불리는 단위로 분리\n",
    "    * 토큰(token)\n",
    "        * 자연어 처리모델이 각 타임스텝에서 단어로 다루는 단위\n",
    "        * 모든 토큰은 사전에 등록되어 있음\n",
    "        * 모든 토큰은 사전에 등록되어 있는 위치 즉, 인덱스로 표현 가능함\n",
    "    * 방법 ( 대표적인 3가지 )\n",
    "        * word-level toknenization\n",
    "        * character-level tokenization\n",
    "        * subword-level tokenization    \n",
    "* BPE Encoding\n",
    "    * BPE 기반의 subword-level tokenization\n",
    "* 형태소(morphs)\n",
    "    * 의미를 가진 가장 작은 단위\n",
    "    * 한국어는 조사, 어미 등을 붙여 말을 만들기 대문에 어절보다는 형태소를 기준으로 토큰화 진행\n",
    "    * 영어는 띄어쓰기 단위, '어절'을 기준으로 토큰화 진행\n",
    "    * 형태소 종류로 어간(stem), 접사(affix) 가 있음\n",
    "        * 어간(stem) : 단어의 의미를 담고 있는 단어의 핵심 부분\n",
    "        * 접사(affix) : 단어에 추가적인 의미를 주는 부분\n",
    "        * cats = cat(어간)-s(접사)\n",
    "* 품사(pos)\n",
    "    * POS : Part Of Speech    \n",
    "* 표제어(lemma)\n",
    "    * lemmatization \n",
    "* 어간 추출(stemming)\n",
    "* 불용어(stopword)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boostcamp (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
