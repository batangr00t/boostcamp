{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c90eb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "torch.Size([])\n",
      "0\n",
      "torch.int64\n",
      "tensor(0.9743)\n",
      "torch.Size([])\n",
      "0\n",
      "torch.float32\n",
      "tensor([[[0.1467, 0.4434, 0.9087, 0.5954, 0.1605],\n",
      "         [0.0402, 0.3145, 0.9023, 0.8484, 0.9718],\n",
      "         [0.8680, 0.0204, 0.2247, 0.2975, 0.7184],\n",
      "         [0.1576, 0.5459, 0.3565, 0.4674, 0.8257]],\n",
      "\n",
      "        [[0.7014, 0.9176, 0.4764, 0.9492, 0.1552],\n",
      "         [0.4160, 0.9869, 0.4227, 0.5630, 0.3277],\n",
      "         [0.5064, 0.4672, 0.5825, 0.7038, 0.1556],\n",
      "         [0.6259, 0.5236, 0.2598, 0.3897, 0.6022]],\n",
      "\n",
      "        [[0.8604, 0.4190, 0.8576, 0.0168, 0.6593],\n",
      "         [0.6359, 0.7755, 0.0363, 0.1991, 0.2901],\n",
      "         [0.4251, 0.4488, 0.8984, 0.0887, 0.7027],\n",
      "         [0.3214, 0.8758, 0.6163, 0.4674, 0.3753]]])\n",
      "tensor(4.4830)\n",
      "torch.Size([])\n",
      "0\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 0-D tensor\n",
    "scalar = torch.tensor(3)   \n",
    "print(scalar)       # tensor(3)\n",
    "print(scalar.shape) # torch.Size([])\n",
    "print(scalar.ndim)  # 0\n",
    "print(scalar.dtype) # torch.int64\n",
    "\n",
    "scalar2 = torch.randn(10).sum()\n",
    "print(scalar2)       # tensor(-0.6778)\n",
    "print(scalar2.shape) # torch.Size([])\n",
    "print(scalar2.ndim)  # 0\n",
    "print(scalar2.dtype) # torch.float32\n",
    "\n",
    "a = torch.rand((3,4,5))\n",
    "print(a)\n",
    "scalar3 = torch.norm(a)\n",
    "print(scalar3)       # tensor(4.4621)\n",
    "print(scalar3.shape) # torch.Size([])\n",
    "print(scalar3.ndim)  # 0\n",
    "print(scalar3.dtype) # torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea85bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "torch.Size([3])\n",
      "1\n",
      "torch.int64\n",
      "tensor([1])\n",
      "torch.Size([1])\n",
      "1\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1-D tensor\n",
    "vector1 = torch.tensor([1,2,3]) # 0-D tensor가 1,2,3 인 배열\n",
    "print(vector1)       # tensor([1, 2, 3])\n",
    "print(vector1.shape) # torch.Size([3])\n",
    "print(vector1.ndim)  # 1\n",
    "print(vector1.dtype) # torch.int64\n",
    "\n",
    "vector2 = torch.randint(5, [1]) # 0-D tensor가 1개인 배열\n",
    "print(vector2)       # tensor([3]), 0-D 텐서인 tensor(3)과 다름\n",
    "print(vector2.shape) # torch.Size([1])\n",
    "print(vector2.ndim)  # 1\n",
    "print(vector2.dtype) # torch.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce3cac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "torch.Size([3, 4])\n",
      "2\n",
      "torch.float32\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]], dtype=torch.float64)\n",
      "torch.Size([4, 4])\n",
      "2\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# 2-D tensor\n",
    "matrix1 = torch.zeros(3, 4) # 1-D tensor가 3개인 배열\n",
    "print(matrix1)\n",
    "print(matrix1.size()) # torch.Size([3, 4])\n",
    "print(matrix1.dim())  # 2\n",
    "print(matrix1.dtype)  # torch.float32\n",
    "\n",
    "matrix2 = torch.eye(4, dtype=torch.double)  # 1-D tensor가 4개인 배열\n",
    "print(matrix2)\n",
    "print(matrix2.size()) # torch.Size([4, 4])\n",
    "print(matrix2.dim())  # 2\n",
    "print(matrix2.dtype)  # torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d11739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[9, 6, 1, 8],\n",
      "         [7, 8, 3, 9],\n",
      "         [4, 3, 5, 5]],\n",
      "\n",
      "        [[1, 0, 9, 0],\n",
      "         [7, 2, 0, 1],\n",
      "         [9, 6, 9, 4]]])\n",
      "tensor(116)\n",
      "tensor([[10,  6, 10,  8],\n",
      "        [14, 10,  3, 10],\n",
      "        [13,  9, 14,  9]])\n",
      "tensor([[20, 17,  9, 22],\n",
      "        [17,  8, 18,  5]])\n",
      "tensor([[24, 27, 17],\n",
      "        [10, 10, 28]])\n",
      "tensor([[24, 27, 17],\n",
      "        [10, 10, 28]])\n",
      "tensor([[20, 17,  9, 22],\n",
      "        [17,  8, 18,  5]])\n",
      "tensor([[10,  6, 10,  8],\n",
      "        [14, 10,  3, 10],\n",
      "        [13,  9, 14,  9]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randint(10, (2,3,4))\n",
    "print(a)\n",
    "\n",
    "# 전체 element 더하여 스칼라 텐서 생성됨, 결과는 0-D tensor\n",
    "result = a.sum()\n",
    "print(result)\n",
    "\n",
    "# dim-0차원 2개의 배열을 더함, 스칼라 탠서로 변하면서 차원이 사라짐 => 결과는 (3,4) shape의 탠서\n",
    "result = a.sum(dim=0)\n",
    "print(result)\n",
    "\n",
    "# dim-1차원 3개의 배열을 더함, 스칼라 텐서로 변하면서 해당 차원이 사라짐 => 결과는 (2,4) shape의 탠서\n",
    "result = a.sum(dim=1)\n",
    "print(result)\n",
    "\n",
    "# dim-2차원 4개의 배열을 더함, 스칼라 텐서로 변하면서 해당 차원이 사라짐 => 결과는 (2,3) shape의 탠서\n",
    "result = a.sum(dim=2)\n",
    "print(result)\n",
    "\n",
    "result = a.sum(dim=-1)\n",
    "print(result)\n",
    "result = a.sum(dim=-2)\n",
    "print(result)\n",
    "result = a.sum(dim=-3)\n",
    "print(result)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a738111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5279, -0.7217, -0.0417],\n",
      "        [ 0.6262, -0.8656,  1.1461]])\n",
      "tensor([[ 0.4970, -0.3481,  0.4370],\n",
      "        [ 1.0724,  0.6319,  1.2457]])\n",
      "tensor([[-1.0309, -1.0699,  0.3954],\n",
      "        [ 1.6986, -0.2337,  2.3918]])\n",
      "tensor([[-1.0309, -1.0699,  0.3954],\n",
      "        [ 1.6986, -0.2337,  2.3918]])\n",
      "tensor([[-2.0249, -0.3736, -0.4787],\n",
      "        [-0.4462, -1.4975, -0.0996]])\n",
      "tensor([[-2.0249, -0.3736, -0.4787],\n",
      "        [-0.4462, -1.4975, -0.0996]])\n",
      "tensor([[-0.7593,  0.2513, -0.0182],\n",
      "        [ 0.6715, -0.5470,  1.4277]])\n",
      "tensor([[-0.7593,  0.2513, -0.0182],\n",
      "        [ 0.6715, -0.5470,  1.4277]])\n",
      "tensor([[-3.0742,  2.0731, -0.0953],\n",
      "        [ 0.5839, -1.3698,  0.9201]])\n",
      "tensor([[-3.0742,  2.0731, -0.0953],\n",
      "        [ 0.5839, -1.3698,  0.9201]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "b = torch.randn(2, 3)\n",
    "print(b)\n",
    "# 2-D tensor + 2-D tensor\n",
    "print(a + b)\n",
    "print(torch.add(a, b))\n",
    "# 2-D tensor - 2-D tensor\n",
    "print(a - b)\n",
    "print(torch.sub(a, b))\n",
    "# 2-D tensor * 2-D tensor\n",
    "print(a * b)\n",
    "print(torch.mul(a, b))\n",
    "# 2-D tensor / 2-D tensor\n",
    "print(a / b)\n",
    "print(torch.div(a, b))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c922b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5304,  0.9952, -0.8663],\n",
      "        [ 0.3556, -1.7313, -0.6063]])\n",
      "tensor([[ 0.2090, -0.9569, -0.9208,  0.0335],\n",
      "        [-1.0305, -1.5582, -0.5516,  0.8989],\n",
      "        [ 0.4671,  0.4139, -0.1767, -0.3024]])\n",
      "tensor([[-1.1105, -3.3737, -1.8051,  1.2078],\n",
      "        [ 1.5752,  2.1064,  0.7348, -1.3609]])\n",
      "tensor([[-1.1105, -3.3737, -1.8051,  1.2078],\n",
      "        [ 1.5752,  2.1064,  0.7348, -1.3609]])\n",
      "tensor([[-1.1105, -3.3737, -1.8051,  1.2078],\n",
      "        [ 1.5752,  2.1064,  0.7348, -1.3609]])\n",
      "tensor([[-1.1105, -3.3737, -1.8051,  1.2078],\n",
      "        [ 1.5752,  2.1064,  0.7348, -1.3609]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 행렬곱\n",
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "b = torch.randn(3, 4)\n",
    "print(b)\n",
    "# 2-D tensor @ 2-D tensor\n",
    "print(a @ b)\n",
    "print(torch.matmul(a, b))\n",
    "# 2-D tensor . 2-D tensor\n",
    "print(a.mm(b))\n",
    "print(torch.mm(a, b))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e9881b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1043, -0.5544,  1.0184],\n",
      "        [ 0.8118,  0.4590, -0.9481]])\n",
      "tensor([[0.1043, 0.5544, 1.0184],\n",
      "        [0.8118, 0.4590, 0.9481]])\n",
      "tensor([[1.4663, 2.1584,    nan],\n",
      "        [0.6235, 1.0939, 2.8180]])\n",
      "tensor([[ 0.1045, -0.5876,     nan],\n",
      "        [ 0.9473,  0.4769, -1.2472]])\n",
      "tensor([[ 0.1039, -0.5062,  0.7945],\n",
      "        [ 0.6819,  0.4303, -0.7588]])\n",
      "tensor([[1., -0., 2.],\n",
      "        [1., 1., -0.]])\n",
      "tensor([[0.1043, 0.0000, 1.0184],\n",
      "        [0.8118, 0.4590, 0.0000]])\n",
      "tensor([[0.9946, 0.8502, 0.5248],\n",
      "        [0.6882, 0.8965, 0.5832]])\n",
      "tensor([[1.0054, 1.1576, 1.5649],\n",
      "        [1.3481, 1.1072, 1.4841]])\n",
      "tensor([[1.1100, 0.5744, 2.7686],\n",
      "        [2.2521, 1.5825, 0.3875]])\n",
      "tensor([[ 0., -1.,  1.],\n",
      "        [ 0.,  0., -1.]])\n",
      "tensor([[-2.2603,     nan,  0.0182],\n",
      "        [-0.2084, -0.7787,     nan]])\n",
      "tensor([[-0.9816,     nan,  0.0079],\n",
      "        [-0.0905, -0.3382,     nan]])\n",
      "tensor([[-3.2609,     nan,  0.0262],\n",
      "        [-0.3007, -1.1234,     nan]])\n",
      "tensor([[-0.1043,  0.5544, -1.0184],\n",
      "        [-0.8118, -0.4590,  0.9481]])\n",
      "tensor([[ 9.5857, -1.8038,  0.9820],\n",
      "        [ 1.2318,  2.1786, -1.0548]])\n",
      "tensor([[ 0., -1.,  1.],\n",
      "        [ 1.,  0., -1.]])\n",
      "tensor([[3.0961,    nan, 0.9909],\n",
      "        [1.1098, 1.4760,    nan]])\n",
      "tensor([[ 1., -1.,  1.],\n",
      "        [ 1.,  1., -1.]])\n",
      "tensor([[ 0.1041, -0.5264,  0.8512],\n",
      "        [ 0.7256,  0.4431, -0.8123]])\n",
      "tensor([[ 0.1045, -0.5832,  1.2037],\n",
      "        [ 0.9040,  0.4753, -1.0966]])\n",
      "tensor([[0.3230,    nan, 1.0091],\n",
      "        [0.9010, 0.6775,    nan]])\n",
      "tensor([[ 0.1047, -0.6191,  1.6221],\n",
      "        [ 1.0544,  0.4942, -1.3928]])\n",
      "tensor([[ 0.1039, -0.5038,  0.7692],\n",
      "        [ 0.6706,  0.4293, -0.7389]])\n",
      "tensor([[0., -0., 1.],\n",
      "        [0., 0., -0.]])\n",
      "tensor([[False, False, False],\n",
      "        [False, False, False]])\n",
      "tensor([[ True, False,  True],\n",
      "        [ True,  True, False]])\n",
      "tensor([[ True, False,  True],\n",
      "        [ True,  True, False]])\n",
      "tensor([[False,  True, False],\n",
      "        [False, False,  True]])\n",
      "tensor([[False,  True, False],\n",
      "        [False, False,  True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(2)\n",
      "tensor(5)\n",
      "tensor(1.0184)\n",
      "tensor(-0.9481)\n",
      "tensor(0.1485)\n",
      "tensor(0.1043)\n",
      "torch.return_types.mode(\n",
      "values=tensor([-0.5544, -0.9481]),\n",
      "indices=tensor([1, 2]))\n",
      "tensor(0.7735)\n",
      "tensor(0.5983)\n",
      "tensor(0.8911)\n",
      "tensor(0.0208)\n",
      "tensor([[ 0.1043, -0.5544,  1.0184],\n",
      "        [ 0.9162, -0.0954,  0.0703]])\n",
      "tensor([[ 0.1043, -0.5544,  1.0184],\n",
      "        [ 0.0847, -0.2545, -0.9655]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[ 0.1043, -0.5544, -0.9481],\n",
      "        [ 0.8118,  0.4590,  1.0184]]),\n",
      "indices=tensor([[0, 0, 1],\n",
      "        [1, 1, 0]]))\n",
      "tensor([[0, 0, 1],\n",
      "        [1, 1, 0]])\n",
      "tensor([-0.9481, -0.5544,  0.1043,  0.4590,  0.8118,  1.0184])\n",
      "tensor([[0.1043, 0.5544, 1.0184],\n",
      "        [0.8118, 0.4590, 0.9481]])\n",
      "tensor([[0, 0],\n",
      "        [0, 1],\n",
      "        [0, 2],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [1, 2]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 공용함수, 삼각함수, 지수함수, 로그함수, 비교함수, 논리함수, 통계함수, 선형대수 함수 등\n",
    "# 모두 tensor를 입력으로 받고 tensor를 출력함\n",
    "a = torch.randn(2, 3)\n",
    "print(a)    \n",
    "print(torch.abs(a))        # 절댓값\n",
    "print(torch.acos(a))       # 아크코사인\n",
    "print(torch.asin(a))       # 아크사인\n",
    "print(torch.atan(a))       # 아크탄젠트\n",
    "print(torch.ceil(a))       # 올림\n",
    "print(torch.clamp(a, min=0.0)) # 최소값 지정\n",
    "print(torch.cos(a))        # 코사인\n",
    "print(torch.cosh(a))       # 쌍곡코사인\n",
    "print(torch.exp(a))        # 지수함수\n",
    "print(torch.floor(a))      # 내림\n",
    "print(torch.log(a))        # 자연로그\n",
    "print(torch.log10(a))      # 상용로그\n",
    "print(torch.log2(a))       # 이진로그\n",
    "print(torch.neg(a))        # 음수\n",
    "print(torch.reciprocal(a)) # 역수\n",
    "print(torch.round(a))      # 반올림\n",
    "print(torch.rsqrt(a))      # 역수의 제곱근\n",
    "print(torch.sign(a))       # 부호\n",
    "print(torch.sin(a))        # 사인\n",
    "print(torch.sinh(a))       # 쌍곡사인\n",
    "print(torch.sqrt(a))       # 제곱근\n",
    "print(torch.tan(a))        # 탄젠트\n",
    "print(torch.tanh(a))       # 쌍곡탄젠트\n",
    "print(torch.trunc(a))      # 정수부분\n",
    "print(torch.eq(a, 0.0))    # 요소별 동일여부\n",
    "print(torch.ge(a, 0.0))    # 요소별 크거나 같은지 여부\n",
    "print(torch.gt(a, 0.0))    # 요소별 큰지 여부\n",
    "print(torch.le(a, 0.0))    # 요소별 작거나 같은지 여부\n",
    "print(torch.lt(a, 0.0))    # 요소별 작은지 여부\n",
    "print(torch.ne(a, 0.0))    # 요소별 같지 않은지 여부\n",
    "print(torch.all(a))        # 모든 요소가 참인지 여부\n",
    "print(torch.any(a))        # 하나 이상의 요소가 참인지 여부\n",
    "print(torch.argmax(a))     # 가장 큰 요소의 인덱스\n",
    "print(torch.argmin(a))     # 가장 작은 요소의 인덱스\n",
    "print(torch.max(a))        # 가장 큰 요소\n",
    "print(torch.min(a))        # 가장 작은 요소\n",
    "print(torch.mean(a))       # 평균\n",
    "print(torch.median(a))     # 중앙값\n",
    "print(torch.mode(a))       # 최빈값\n",
    "print(torch.std(a))        # 표준편차\n",
    "print(torch.var(a))        # 분산\n",
    "print(torch.sum(a))        # 합 \n",
    "print(torch.prod(a))       # 곱\n",
    "print(torch.cumsum(a, dim=0)) # 누적합\n",
    "print(torch.cumprod(a, dim=0))# 누적곱\n",
    "print(torch.sort(a, dim=0))   # 정렬\n",
    "print(torch.argsort(a, dim=0))# 정렬된 인덱스\n",
    "print(torch.unique(a))        # 중복제거\n",
    "print(torch.where(a>0, a, -a))# 조건에 따라 값 선택\n",
    "print(torch.nonzero(a))      # 0이 아닌 요소의 인덱스\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0166aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "tensor([[False,  True,  True],\n",
      "        [ True, False,  True]])\n",
      "tensor([[False,  True,  True],\n",
      "        [ True, False,  True]])\n",
      "tensor([[ True, False, False],\n",
      "        [False,  True, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 논리함수, 텐서 출력\n",
    "a = torch.randint(9, (2, 3))\n",
    "b = torch.randint(9, (2, 3))\n",
    "print(\"-\"*20)\n",
    "c = a.logical_and(b) # 요소별 논리 AND\n",
    "print(c)\n",
    "c = a.logical_or(b)  # 요소별 논리 OR\n",
    "print(c)\n",
    "c = c.logical_not()  # 요소별 논리 NOT  \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d0fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2330, -1.2627,  0.3231],\n",
      "        [ 0.7488, -0.6954,  0.3175]])\n",
      "tensor([ 0.2330, -1.2627,  0.3231,  0.7488, -0.6954,  0.3175])\n",
      "tensor([[ 0.2330, -1.2627],\n",
      "        [ 0.3231,  0.7488],\n",
      "        [-0.6954,  0.3175]])\n",
      "tensor([[ 0.2330,  0.7488],\n",
      "        [-1.2627, -0.6954],\n",
      "        [ 0.3231,  0.3175]])\n",
      "tensor([[ 0.2330,  0.7488],\n",
      "        [-1.2627, -0.6954],\n",
      "        [ 0.3231,  0.3175]])\n",
      "tensor([[[ 0.2330, -1.2627,  0.3231],\n",
      "         [ 0.7488, -0.6954,  0.3175]]])\n",
      "tensor([[[ 0.2330, -1.2627,  0.3231]],\n",
      "\n",
      "        [[ 0.7488, -0.6954,  0.3175]]])\n",
      "tensor([[[ 0.2330],\n",
      "         [-1.2627],\n",
      "         [ 0.3231]],\n",
      "\n",
      "        [[ 0.7488],\n",
      "         [-0.6954],\n",
      "         [ 0.3175]]])\n",
      "tensor([[ 0.2330, -1.2627,  0.3231],\n",
      "        [ 0.7488, -0.6954,  0.3175]])\n",
      "tensor([[ 0.2330, -1.2627,  0.3231],\n",
      "        [ 0.7488, -0.6954,  0.3175]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 텐서 변형 함수\n",
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "\n",
    "print(torch.flatten(a))      # 다차원 텐서를 1-D tensor로 변환\n",
    "print(torch.reshape(a, (3,2))) # 텐서의 shape 변경\n",
    "print(torch.transpose(a, 0, 1)) # 텐서의 차원 교환\n",
    "print(torch.t(a))            # 2-D tensor의 전치행렬\n",
    "print(torch.unsqueeze(a, 0)) # 지정한 위치에 차원 추가\n",
    "print(torch.unsqueeze(a, 1)) # 지정한 위치에 차원 추가\n",
    "print(torch.unsqueeze(a, 2)) # 지정한 위치에 차원 추가\n",
    "print(torch.squeeze(a))      # 크기가 1인 차원 제거\n",
    "print(torch.squeeze(torch.unsqueeze(a, 0))) # 크기가 1인 차원 제거\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ba9632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 4, 2],\n",
      "        [6, 2, 8]])\n",
      "--------------------\n",
      "tensor([[3, 4, 2],\n",
      "        [6, 2, 8],\n",
      "        [3, 4, 2],\n",
      "        [6, 2, 8]])\n",
      "torch.Size([4, 3])\n",
      "--------------------\n",
      "tensor([[3, 4, 2, 3, 4, 2],\n",
      "        [6, 2, 8, 6, 2, 8]])\n",
      "torch.Size([2, 6])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 텐서 결합 함수 cat\n",
    "a = torch.randint(9, (2, 3))\n",
    "print(a)\n",
    "\n",
    "print(\"-\"*20)\n",
    "b = torch.cat([a, a], dim=0)  # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)\n",
    "b = torch.cat([a, a], dim=1) # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13e5572f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 8, 6, 0],\n",
      "        [6, 0, 3, 5],\n",
      "        [7, 6, 6, 4]])\n",
      "torch.Size([3, 4])\n",
      "--------------------\n",
      "tensor([[[5, 8, 6, 0],\n",
      "         [6, 0, 3, 5],\n",
      "         [7, 6, 6, 4]],\n",
      "\n",
      "        [[5, 8, 6, 0],\n",
      "         [6, 0, 3, 5],\n",
      "         [7, 6, 6, 4]]])\n",
      "torch.Size([2, 3, 4])\n",
      "--------------------\n",
      "tensor([[[5, 8, 6, 0],\n",
      "         [5, 8, 6, 0]],\n",
      "\n",
      "        [[6, 0, 3, 5],\n",
      "         [6, 0, 3, 5]],\n",
      "\n",
      "        [[7, 6, 6, 4],\n",
      "         [7, 6, 6, 4]]])\n",
      "torch.Size([3, 2, 4])\n",
      "--------------------\n",
      "tensor([[[5, 5],\n",
      "         [8, 8],\n",
      "         [6, 6],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[6, 6],\n",
      "         [0, 0],\n",
      "         [3, 3],\n",
      "         [5, 5]],\n",
      "\n",
      "        [[7, 7],\n",
      "         [6, 6],\n",
      "         [6, 6],\n",
      "         [4, 4]]])\n",
      "torch.Size([3, 4, 2])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 텐서 결합 함수 stack\n",
    "a = torch.randint(9, (3,4))\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(\"-\"*20)\n",
    "b = torch.stack([a, a], dim=0) # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)\n",
    "b = torch.stack([a, a], dim=1) # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)\n",
    "b = torch.stack([a, a], dim=2) # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10afebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5000])\n",
      "3.5\n",
      "torch.Size([1])\n",
      "1\n",
      "False\n",
      "tensor([False])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# tensor가 아닌 Python 기본 타입을 출력하는 경우\n",
    "a = torch.tensor([3.5])\n",
    "print(a)\n",
    "\n",
    "# 스칼라 텐서의 값을 Python 기본 타입으로 반환 \n",
    "print(a.item())  \n",
    "\n",
    "#크기/차원 정보\n",
    "print(a.size()) # torch.Size([1])\n",
    "print(a.numel()) # 1, 텐서의 모든 요소 개수\n",
    "\n",
    "# 전체 동등성 검사, 결과는 bool\n",
    "b = torch.tensor([2.5])\n",
    "print(a.equal(b))\n",
    "\n",
    "# 요소별 동등성 검사, 결과는 tensor\n",
    "print(a == b)      # tensor([False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e7c5de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 8, 2],\n",
      "        [7, 0, 1]])\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 일부 검사함수\n",
    "a = torch.randint(9, (2, 3))\n",
    "print(a)   \n",
    "b = a.is_floating_point() # 실수형 여부\n",
    "print(b)\n",
    "b = a.is_complex()       # 복소수형 여부\n",
    "print(b)\n",
    "b = a.is_same_size(a)    # 동일한 shape인지 여부\n",
    "print(b)    \n",
    "b = a.is_contiguous()    # 메모리상에 연속적으로 저장되어 있는지 여부\n",
    "print(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e4eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6001, 0.4721, 0.9981],\n",
      "        [0.1062, 0.0771, 0.6550]])\n",
      "tensor([0.6094, 0.4784, 1.1938])\n",
      "tensor([1.2567, 0.6680])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((2, 3))\n",
    "print(a)\n",
    "\n",
    "b = a.norm(p=2, dim=0) # 열벡터의 L2 norm 계산\n",
    "print(b)\n",
    "b = a.norm(p=2, dim=1) # 행벡터의 L2 norm 계산\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "658658d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = torch.randn(5, 3).numpy() # 5개의 샘플과 3개의 특성\n",
    "y = torch.randn(5).numpy()    # 5개의 샘플에 대한 타겟 값\n",
    "\n",
    "# X에 적용할 scaler 객체 생성\n",
    "scaler = StandardScaler().fit(X)\n",
    "# y에 적용할 scaler 객체 생성\n",
    "scaler_y = StandardScaler().fit(y.reshape(-1, 1))\n",
    "# X에 transform 적용\n",
    "X_scaled = scaler.transform(X)\n",
    "# y에 transform 적용\n",
    "y_scaled = scaler_y.transform(y.reshape(-1, 1)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceed9ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9652, 0.1775, 0.4340],\n",
      "        [0.4004, 0.9515, 0.5338]])\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 1.]]\n",
      "tensor([[0.7945, 0.4032, 0.8754],\n",
      "        [0.2081, 0.1681, 0.5706]])\n",
      "[[0.6360772  0.32276872 0.7008753 ]\n",
      " [0.33024856 0.26670748 0.9054297 ]]\n",
      "tensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "a = torch.rand((2,3))\n",
    "print(a)\n",
    "b = mm.fit_transform(a)\n",
    "print(b)\n",
    "\n",
    "norm = Normalizer(norm='l2')\n",
    "a = torch.rand((2,3))\n",
    "print(a)\n",
    "b = norm.fit_transform(a)\n",
    "print(b)\n",
    "print(torch.norm(torch.tensor(b), p=2, dim=1))  # 행벡터의 L2 norm 계산, 모두 1.0이 나옴\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3ec684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6898,  0.6810,  0.4189, -0.4413,  0.1932],\n",
      "        [-0.4704, -0.1546, -0.2401,  1.3012,  0.3067],\n",
      "        [ 0.2017,  0.4894,  0.1515, -0.3606, -1.1360]])\n",
      "tensor([[-0.4609,  0.5594,  0.2620, -0.4065, -0.1208],\n",
      "        [-0.7889, -0.7115,  0.7230, -0.3857, -0.5172],\n",
      "        [-0.3409,  0.2743, -0.0330, -0.7731,  0.3041]])\n",
      "tensor([[-0.9444, -0.4362, -0.5706, -0.4035, -0.4431],\n",
      "        [ 0.9654, -0.0454,  1.2910, -0.2830, -0.8608],\n",
      "        [-1.3790,  0.7629, -0.8594,  0.0178,  0.3878]])\n",
      "tensor([[-0.6204,  0.1156, -0.8824, -0.8385, -0.5180],\n",
      "        [-0.7299,  0.0025,  0.4165, -0.4534,  0.6242],\n",
      "        [ 0.0420, -0.8638, -0.2323,  0.9321, -0.8336]])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "weight = torch.empty(3, 5)\n",
    "\n",
    "# sigmoid\n",
    "nn.init.xavier_normal_(weight)\n",
    "print(weight)\n",
    "nn.init.xavier_uniform_(weight)\n",
    "print(weight)\n",
    "\n",
    "# ReLU\n",
    "nn.init.kaiming_normal_(weight, mode='fan_in', nonlinearity='relu')\n",
    "print(weight)\n",
    "nn.init.kaiming_uniform_(weight, mode='fan_in', nonlinearity='relu')\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "59d05e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape, y_train.shape\n",
      "torch.Size([1000, 3]) torch.Size([1000, 1])\n",
      "X_test1.shape, y_test1.shape, X_test2.shape, y_test2.shape\n",
      "torch.Size([200, 3]) torch.Size([200, 1]) torch.Size([200, 3]) torch.Size([200, 1])\n",
      "63 13 13\n",
      "Parameter containing:\n",
      "tensor([[-0.1364, -0.5050,  0.3335]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3651], requires_grad=True)\n",
      "MultipleLinearRegressionModel(\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "===================== Training the model\n",
      "Epoch 1/20, Train Loss: 3697.1049\n",
      "Epoch 2/20, Train Loss: 330.6601\n",
      "Epoch 3/20, Train Loss: 30.6050\n",
      "Epoch 4/20, Train Loss: 3.6997\n",
      "Epoch 5/20, Train Loss: 1.2268\n",
      "Epoch 6/20, Train Loss: 0.9945\n",
      "Epoch 7/20, Train Loss: 0.9726\n",
      "Epoch 8/20, Train Loss: 0.9716\n",
      "Epoch 9/20, Train Loss: 0.9717\n",
      "Epoch 10/20, Train Loss: 0.9717\n",
      "Epoch 11/20, Train Loss: 0.9715\n",
      "Epoch 12/20, Train Loss: 0.9711\n",
      "Epoch 13/20, Train Loss: 0.9709\n",
      "Epoch 14/20, Train Loss: 0.9711\n",
      "Epoch 15/20, Train Loss: 0.9718\n",
      "Epoch 16/20, Train Loss: 0.9720\n",
      "Epoch 17/20, Train Loss: 0.9711\n",
      "Epoch 18/20, Train Loss: 0.9715\n",
      "Epoch 19/20, Train Loss: 0.9708\n",
      "Epoch 20/20, Train Loss: 0.9714\n",
      "Parameter containing:\n",
      "tensor([[ 0.9988,  9.9674, 99.9407]], requires_grad=True) Parameter containing:\n",
      "tensor([0.0507], requires_grad=True)\n",
      "===================== Evaluating on Test1 and Test2 datasets\n",
      "Test1 평균 Loss: 0.0064\n",
      "Test2 평균 Loss: 0.7830\n",
      "=================== coef 차이\n",
      "tensor([[-0.0495],\n",
      "        [-0.0181],\n",
      "        [ 0.0086]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Multiple Linear Regression\n",
    "# 문제 정의 : y = a*x1 + b*x2 + c*x3 + noise\n",
    "# \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Training data generation\n",
    "traing_data_size = 1000\n",
    "X_train = torch.randn(traing_data_size, 3)\n",
    "coef = torch.tensor([1., 10., 100.]).unsqueeze(1)\n",
    "noise = torch.randn(traing_data_size, 1)\n",
    "y_train = X_train.mm(coef) + noise\n",
    "print(\"X_train.shape, y_train.shape\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "      \n",
    "# Test data generation,\n",
    "# test1, test2 두 종류의 테스트 데이터 생성\n",
    "# 각각 다른 분포를 가진 테스트 데이터도 잘 예측하는지 확인하기 위함\n",
    "test_data_size = 200\n",
    "X_test1 = torch.randn(test_data_size, 3)\n",
    "y_test1 = X_test1.mm(coef)\n",
    "X_test2 = torch.randn(test_data_size, 3) + 10.0\n",
    "y_test2 = X_test2.mm(coef)\n",
    "print(\"X_test1.shape, y_test1.shape, X_test2.shape, y_test2.shape\") \n",
    "print(X_test1.shape, y_test1.shape, X_test2.shape, y_test2.shape)   \n",
    "\n",
    "# 데이터 로더 정의\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test1_dataset = TensorDataset(X_test1, y_test1)\n",
    "test1_dataloader = DataLoader(test1_dataset, batch_size=16, shuffle=False)\n",
    "test2_dataset = TensorDataset(X_test2, y_test2)\n",
    "test2_dataloader = DataLoader(test2_dataset, batch_size=16, shuffle=False)\n",
    "print(len(train_dataloader), len(test1_dataloader), len(test2_dataloader))\n",
    "\n",
    "# 모델 정의\n",
    "class MultipleLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        in_size, out_size = len(coef), 1\n",
    "        self.linear = nn.Linear(in_size, out_size)  # 입력 특성 3개, 출력 특성 1개\n",
    "        print(self.linear.weight)\n",
    "        print(self.linear.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = MultipleLinearRegressionModel()\n",
    "print(model)\n",
    "\n",
    "# 손실함수 정의\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 옵티마이저 정의\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train(model, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for inputs, targets in dataloader:\n",
    "        optimizer.zero_grad()           # 옵티마이저 초기화\n",
    "        outputs = model(inputs)         # 모델에 입력 데이터 전달하여 출력 계산\n",
    "        loss = criterion(outputs, targets) # 손실함수 계산\n",
    "        loss.backward()                 # 역전파 수행하여 그래디언트 계산\n",
    "        optimizer.step()                # 옵티마이저 스텝 수행하여 모델 파라미터 업데이트\n",
    "        total_loss += loss.item() * inputs.size(dim=0) # 배치 손실 합산\n",
    "        \n",
    "    avg_loss = total_loss / len(dataloader.dataset) # 평균 손실 계산\n",
    "    return avg_loss\n",
    "\n",
    "# 모델 학습\n",
    "print(\"===================== Training the model\")\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "print(model.linear.weight, model.linear.bias)\n",
    "\n",
    "# 모델 평가\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():  # 평가 시에는 그래디언트 계산을 하지 않음\n",
    "        for inputs, targets in dataloader:\n",
    "            outputs = model(inputs)         # 모델에 입력 데이터 전달하여 출력 계산\n",
    "            loss = criterion(outputs, targets) # 손실함수 계산\n",
    "            total_loss += loss.item() * inputs.size(dim=0) # 배치 손실 합산\n",
    "            \n",
    "    avg_loss = total_loss / len(dataloader.dataset) # 평균 손실 계산\n",
    "    return avg_loss\n",
    "\n",
    "print(\"===================== Evaluating on Test1 and Test2 datasets\")\n",
    "test1_loss = evaluate(model, test1_dataloader)\n",
    "print(f\"Test1 평균 Loss: {test1_loss:.4f}\")\n",
    "test2_loss = evaluate(model, test2_dataloader)\n",
    "print(f\"Test2 평균 Loss: {test2_loss:.4f}\")\n",
    "\n",
    "print(\"=================== coef 차이\")\n",
    "c = model(torch.eye(len(coef)).float())\n",
    "print(coef-c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8d4a71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html 따라해 보기\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data 다운로드\n",
    "traing_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# 데이터 로더 정의\n",
    "# 모델 정의\n",
    "# 손실 함수 정의\n",
    "# 옵티마이저 정의\n",
    "# 모델 학습\n",
    "# 모델 평가\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boostcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
