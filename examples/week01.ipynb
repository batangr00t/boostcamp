{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fae2111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c90eb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "torch.Size([])\n",
      "0\n",
      "torch.int64\n",
      "tensor(-3.7479)\n",
      "torch.Size([])\n",
      "0\n",
      "torch.float32\n",
      "tensor([[[0.3227, 0.6038, 0.1653, 0.6338, 0.5041],\n",
      "         [0.7668, 0.5388, 0.2554, 0.7792, 0.0989],\n",
      "         [0.3374, 0.4285, 0.6398, 0.5788, 0.4403],\n",
      "         [0.5941, 0.4049, 0.6454, 0.3858, 0.2043]],\n",
      "\n",
      "        [[0.8329, 0.0767, 0.9926, 0.4648, 0.0053],\n",
      "         [0.2595, 0.9331, 0.4218, 0.2538, 0.5858],\n",
      "         [0.5930, 0.9648, 0.0621, 0.5225, 0.4520],\n",
      "         [0.8334, 0.3594, 0.0120, 0.3373, 0.4600]],\n",
      "\n",
      "        [[0.5776, 0.0787, 0.1733, 0.8930, 0.8688],\n",
      "         [0.3109, 0.2024, 0.0287, 0.6448, 0.2256],\n",
      "         [0.6729, 0.0285, 0.8323, 0.2145, 0.0516],\n",
      "         [0.3094, 0.4027, 0.8591, 0.7421, 0.4169]]])\n",
      "tensor(4.1051)\n",
      "torch.Size([])\n",
      "0\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 0-D tensor\n",
    "scalar = torch.tensor(3)   \n",
    "print(scalar)       # tensor(3)\n",
    "print(scalar.shape) # torch.Size([])\n",
    "print(scalar.ndim)  # 0\n",
    "print(scalar.dtype) # torch.int64\n",
    "\n",
    "scalar2 = torch.randn(10).sum()\n",
    "print(scalar2)       # tensor(-0.6778)\n",
    "print(scalar2.shape) # torch.Size([])\n",
    "print(scalar2.ndim)  # 0\n",
    "print(scalar2.dtype) # torch.float32\n",
    "\n",
    "a = torch.rand((3,4,5))\n",
    "print(a)\n",
    "scalar3 = torch.norm(a)\n",
    "print(scalar3)       # tensor(4.4621)\n",
    "print(scalar3.shape) # torch.Size([])\n",
    "print(scalar3.ndim)  # 0\n",
    "print(scalar3.dtype) # torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea85bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "torch.Size([3])\n",
      "1\n",
      "torch.int64\n",
      "tensor([1])\n",
      "torch.Size([1])\n",
      "1\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# 1-D tensor\n",
    "vector1 = torch.tensor([1,2,3]) # 0-D tensor가 1,2,3 인 배열\n",
    "print(vector1)       # tensor([1, 2, 3])\n",
    "print(vector1.shape) # torch.Size([3])\n",
    "print(vector1.ndim)  # 1\n",
    "print(vector1.dtype) # torch.int64\n",
    "\n",
    "vector2 = torch.randint(5, [1]) # 0-D tensor가 1개인 배열\n",
    "print(vector2)       # tensor([3]), 0-D 텐서인 tensor(3)과 다름\n",
    "print(vector2.shape) # torch.Size([1])\n",
    "print(vector2.ndim)  # 1\n",
    "print(vector2.dtype) # torch.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce3cac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "torch.Size([3, 4])\n",
      "2\n",
      "torch.float32\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]], dtype=torch.float64)\n",
      "torch.Size([4, 4])\n",
      "2\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# 2-D tensor\n",
    "matrix1 = torch.zeros(3, 4) # 1-D tensor가 3개인 배열\n",
    "print(matrix1)\n",
    "print(matrix1.size()) # torch.Size([3, 4])\n",
    "print(matrix1.dim())  # 2\n",
    "print(matrix1.dtype)  # torch.float32\n",
    "\n",
    "matrix2 = torch.eye(4, dtype=torch.double)  # 1-D tensor가 4개인 배열\n",
    "print(matrix2)\n",
    "print(matrix2.size()) # torch.Size([4, 4])\n",
    "print(matrix2.dim())  # 2\n",
    "print(matrix2.dtype)  # torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d11739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[6, 9, 1, 6],\n",
      "         [6, 7, 2, 7],\n",
      "         [8, 4, 3, 0]],\n",
      "\n",
      "        [[0, 0, 3, 1],\n",
      "         [3, 3, 3, 2],\n",
      "         [4, 9, 2, 8]]])\n",
      "tensor(97)\n",
      "tensor([[ 6,  9,  4,  7],\n",
      "        [ 9, 10,  5,  9],\n",
      "        [12, 13,  5,  8]])\n",
      "tensor([[20, 20,  6, 13],\n",
      "        [ 7, 12,  8, 11]])\n",
      "tensor([[22, 22, 15],\n",
      "        [ 4, 11, 23]])\n",
      "tensor([[22, 22, 15],\n",
      "        [ 4, 11, 23]])\n",
      "tensor([[20, 20,  6, 13],\n",
      "        [ 7, 12,  8, 11]])\n",
      "tensor([[ 6,  9,  4,  7],\n",
      "        [ 9, 10,  5,  9],\n",
      "        [12, 13,  5,  8]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(10, (2,3,4))\n",
    "print(a)\n",
    "\n",
    "# 전체 element 더하여 스칼라 텐서 생성됨, 결과는 0-D tensor\n",
    "result = a.sum()\n",
    "print(result)\n",
    "\n",
    "# dim-0차원 2개의 배열을 더함, 스칼라 탠서로 변하면서 차원이 사라짐 => 결과는 (3,4) shape의 탠서\n",
    "result = a.sum(dim=0)\n",
    "print(result)\n",
    "\n",
    "# dim-1차원 3개의 배열을 더함, 스칼라 텐서로 변하면서 해당 차원이 사라짐 => 결과는 (2,4) shape의 탠서\n",
    "result = a.sum(dim=1)\n",
    "print(result)\n",
    "\n",
    "# dim-2차원 4개의 배열을 더함, 스칼라 텐서로 변하면서 해당 차원이 사라짐 => 결과는 (2,3) shape의 탠서\n",
    "result = a.sum(dim=2)\n",
    "print(result)\n",
    "\n",
    "result = a.sum(dim=-1)\n",
    "print(result)\n",
    "result = a.sum(dim=-2)\n",
    "print(result)\n",
    "result = a.sum(dim=-3)\n",
    "print(result)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a738111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5279, -0.7217, -0.0417],\n",
      "        [ 0.6262, -0.8656,  1.1461]])\n",
      "tensor([[ 0.4970, -0.3481,  0.4370],\n",
      "        [ 1.0724,  0.6319,  1.2457]])\n",
      "tensor([[-1.0309, -1.0699,  0.3954],\n",
      "        [ 1.6986, -0.2337,  2.3918]])\n",
      "tensor([[-1.0309, -1.0699,  0.3954],\n",
      "        [ 1.6986, -0.2337,  2.3918]])\n",
      "tensor([[-2.0249, -0.3736, -0.4787],\n",
      "        [-0.4462, -1.4975, -0.0996]])\n",
      "tensor([[-2.0249, -0.3736, -0.4787],\n",
      "        [-0.4462, -1.4975, -0.0996]])\n",
      "tensor([[-0.7593,  0.2513, -0.0182],\n",
      "        [ 0.6715, -0.5470,  1.4277]])\n",
      "tensor([[-0.7593,  0.2513, -0.0182],\n",
      "        [ 0.6715, -0.5470,  1.4277]])\n",
      "tensor([[-3.0742,  2.0731, -0.0953],\n",
      "        [ 0.5839, -1.3698,  0.9201]])\n",
      "tensor([[-3.0742,  2.0731, -0.0953],\n",
      "        [ 0.5839, -1.3698,  0.9201]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "b = torch.randn(2, 3)\n",
    "print(b)\n",
    "# 2-D tensor + 2-D tensor\n",
    "print(a + b)\n",
    "print(torch.add(a, b))\n",
    "# 2-D tensor - 2-D tensor\n",
    "print(a - b)\n",
    "print(torch.sub(a, b))\n",
    "# 2-D tensor * 2-D tensor\n",
    "print(a * b)\n",
    "print(torch.mul(a, b))\n",
    "# 2-D tensor / 2-D tensor\n",
    "print(a / b)\n",
    "print(torch.div(a, b))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c922b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5304,  0.9952, -0.8663],\n",
      "        [ 0.3556, -1.7313, -0.6063]])\n",
      "tensor([[ 0.2090, -0.9569, -0.9208,  0.0335],\n",
      "        [-1.0305, -1.5582, -0.5516,  0.8989],\n",
      "        [ 0.4671,  0.4139, -0.1767, -0.3024]])\n",
      "tensor([[-1.1105, -3.3737, -1.8051,  1.2078],\n",
      "        [ 1.5752,  2.1064,  0.7348, -1.3609]])\n",
      "tensor([[-1.1105, -3.3737, -1.8051,  1.2078],\n",
      "        [ 1.5752,  2.1064,  0.7348, -1.3609]])\n",
      "tensor([[-1.1105, -3.3737, -1.8051,  1.2078],\n",
      "        [ 1.5752,  2.1064,  0.7348, -1.3609]])\n",
      "tensor([[-1.1105, -3.3737, -1.8051,  1.2078],\n",
      "        [ 1.5752,  2.1064,  0.7348, -1.3609]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 행렬곱\n",
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "b = torch.randn(3, 4)\n",
    "print(b)\n",
    "# 2-D tensor @ 2-D tensor\n",
    "print(a @ b)\n",
    "print(torch.matmul(a, b))\n",
    "# 2-D tensor . 2-D tensor\n",
    "print(a.mm(b))\n",
    "print(torch.mm(a, b))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e9881b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2716, -0.3512, -0.6278],\n",
      "        [-0.2553,  0.9899,  1.5630]])\n",
      "tensor([[1.2716, 0.3512, 0.6278],\n",
      "        [0.2553, 0.9899, 1.5630]])\n",
      "tensor([[   nan, 1.9297, 2.2496],\n",
      "        [1.8290, 0.1426,    nan]])\n",
      "tensor([[    nan, -0.3589, -0.6788],\n",
      "        [-0.2582,  1.4282,     nan]])\n",
      "tensor([[ 0.9044, -0.3377, -0.5606],\n",
      "        [-0.2500,  0.7803,  1.0016]])\n",
      "tensor([[2., -0., -0.],\n",
      "        [-0., 1., 2.]])\n",
      "tensor([[1.2716, 0.0000, 0.0000],\n",
      "        [0.0000, 0.9899, 1.5630]])\n",
      "tensor([[0.2947, 0.9390, 0.8093],\n",
      "        [0.9676, 0.5488, 0.0078]])\n",
      "tensor([[1.9235, 1.0623, 1.2036],\n",
      "        [1.0328, 1.5312, 2.4912]])\n",
      "tensor([[3.5667, 0.7038, 0.5337],\n",
      "        [0.7747, 2.6908, 4.7729]])\n",
      "tensor([[ 1., -1., -1.],\n",
      "        [-1.,  0.,  1.]])\n",
      "tensor([[ 0.2403,     nan,     nan],\n",
      "        [    nan, -0.0102,  0.4466]])\n",
      "tensor([[ 0.1044,     nan,     nan],\n",
      "        [    nan, -0.0044,  0.1939]])\n",
      "tensor([[ 0.3467,     nan,     nan],\n",
      "        [    nan, -0.0147,  0.6443]])\n",
      "tensor([[-1.2716,  0.3512,  0.6278],\n",
      "        [ 0.2553, -0.9899, -1.5630]])\n",
      "tensor([[ 0.7864, -2.8473, -1.5928],\n",
      "        [-3.9167,  1.0103,  0.6398]])\n",
      "tensor([[ 1., -0., -1.],\n",
      "        [-0.,  1.,  2.]])\n",
      "tensor([[0.8868,    nan,    nan],\n",
      "        [   nan, 1.0051, 0.7999]])\n",
      "tensor([[ 1., -1., -1.],\n",
      "        [-1.,  1.,  1.]])\n",
      "tensor([[ 0.9556, -0.3440, -0.5874],\n",
      "        [-0.2526,  0.8359,  1.0000]])\n",
      "tensor([[ 1.6431, -0.3585, -0.6699],\n",
      "        [-0.2581,  1.1596,  2.2817]])\n",
      "tensor([[1.1277,    nan,    nan],\n",
      "        [   nan, 0.9949, 1.2502]])\n",
      "tensor([[  3.2423,  -0.3664,  -0.7258],\n",
      "        [ -0.2610,   1.5232, 127.4458]])\n",
      "tensor([[ 0.8542, -0.3374, -0.5566],\n",
      "        [-0.2499,  0.7573,  0.9159]])\n",
      "tensor([[1., -0., -0.],\n",
      "        [-0., 0., 1.]])\n",
      "tensor([[False, False, False],\n",
      "        [False, False, False]])\n",
      "tensor([[ True, False, False],\n",
      "        [False,  True,  True]])\n",
      "tensor([[ True, False, False],\n",
      "        [False,  True,  True]])\n",
      "tensor([[False,  True,  True],\n",
      "        [ True, False, False]])\n",
      "tensor([[False,  True,  True],\n",
      "        [ True, False, False]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(5)\n",
      "tensor(2)\n",
      "tensor(1.5630)\n",
      "tensor(-0.6278)\n",
      "tensor(0.4317)\n",
      "tensor(-0.2553)\n",
      "torch.return_types.mode(\n",
      "values=tensor([-0.6278, -0.2553]),\n",
      "indices=tensor([2, 0]))\n",
      "tensor(0.9491)\n",
      "tensor(0.9009)\n",
      "tensor(2.5901)\n",
      "tensor(-0.1108)\n",
      "tensor([[ 1.2716, -0.3512, -0.6278],\n",
      "        [ 1.0163,  0.6386,  0.9351]])\n",
      "tensor([[ 1.2716, -0.3512, -0.6278],\n",
      "        [-0.3247, -0.3476, -0.9813]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[-0.2553, -0.3512, -0.6278],\n",
      "        [ 1.2716,  0.9899,  1.5630]]),\n",
      "indices=tensor([[1, 0, 0],\n",
      "        [0, 1, 1]]))\n",
      "tensor([[1, 0, 0],\n",
      "        [0, 1, 1]])\n",
      "tensor([-0.6278, -0.3512, -0.2553,  0.9899,  1.2716,  1.5630])\n",
      "tensor([[1.2716, 0.3512, 0.6278],\n",
      "        [0.2553, 0.9899, 1.5630]])\n",
      "tensor([[0, 0],\n",
      "        [0, 1],\n",
      "        [0, 2],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [1, 2]])\n"
     ]
    }
   ],
   "source": [
    "# 공용함수, 삼각함수, 지수함수, 로그함수, 비교함수, 논리함수, 통계함수, 선형대수 함수 등\n",
    "a = torch.randn(2, 3)\n",
    "print(a)    \n",
    "print(torch.abs(a))        # 절댓값\n",
    "print(torch.acos(a))       # 아크코사인\n",
    "print(torch.asin(a))       # 아크사인\n",
    "print(torch.atan(a))       # 아크탄젠트\n",
    "print(torch.ceil(a))       # 올림\n",
    "print(torch.clamp(a, min=0.0)) # 최소값 지정\n",
    "print(torch.cos(a))        # 코사인\n",
    "print(torch.cosh(a))       # 쌍곡코사인\n",
    "print(torch.exp(a))        # 지수함수\n",
    "print(torch.floor(a))      # 내림\n",
    "print(torch.log(a))        # 자연로그\n",
    "print(torch.log10(a))      # 상용로그\n",
    "print(torch.log2(a))       # 이진로그\n",
    "print(torch.neg(a))        # 음수\n",
    "print(torch.reciprocal(a)) # 역수\n",
    "print(torch.round(a))      # 반올림\n",
    "print(torch.rsqrt(a))      # 역수의 제곱근\n",
    "print(torch.sign(a))       # 부호\n",
    "print(torch.sin(a))        # 사인\n",
    "print(torch.sinh(a))       # 쌍곡사인\n",
    "print(torch.sqrt(a))       # 제곱근\n",
    "print(torch.tan(a))        # 탄젠트\n",
    "print(torch.tanh(a))       # 쌍곡탄젠트\n",
    "print(torch.trunc(a))      # 정수부분\n",
    "print(torch.eq(a, 0.0))    # 요소별 동일여부\n",
    "print(torch.ge(a, 0.0))    # 요소별 크거나 같은지 여부\n",
    "print(torch.gt(a, 0.0))    # 요소별 큰지 여부\n",
    "print(torch.le(a, 0.0))    # 요소별 작거나 같은지 여부\n",
    "print(torch.lt(a, 0.0))    # 요소별 작은지 여부\n",
    "print(torch.ne(a, 0.0))    # 요소별 같지 않은지 여부\n",
    "print(torch.all(a))        # 모든 요소가 참인지 여부\n",
    "print(torch.any(a))        # 하나 이상의 요소가 참인지 여부\n",
    "print(torch.argmax(a))     # 가장 큰 요소의 인덱스\n",
    "print(torch.argmin(a))     # 가장 작은 요소의 인덱스\n",
    "print(torch.max(a))        # 가장 큰 요소\n",
    "print(torch.min(a))        # 가장 작은 요소\n",
    "print(torch.mean(a))       # 평균\n",
    "print(torch.median(a))     # 중앙값\n",
    "print(torch.mode(a))       # 최빈값\n",
    "print(torch.std(a))        # 표준편차\n",
    "print(torch.var(a))        # 분산\n",
    "print(torch.sum(a))        # 합 \n",
    "print(torch.prod(a))       # 곱\n",
    "print(torch.cumsum(a, dim=0)) # 누적합\n",
    "print(torch.cumprod(a, dim=0))# 누적곱\n",
    "print(torch.sort(a, dim=0))   # 정렬\n",
    "print(torch.argsort(a, dim=0))# 정렬된 인덱스\n",
    "print(torch.unique(a))        # 중복제거\n",
    "print(torch.where(a>0, a, -a))# 조건에 따라 값 선택\n",
    "print(torch.nonzero(a))      # 0이 아닌 요소의 인덱스\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0166aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "tensor([[ True,  True,  True],\n",
      "        [ True, False,  True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[False, False, False],\n",
      "        [False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(9, (2, 3))\n",
    "b = torch.randint(9, (2, 3))\n",
    "print(\"-\"*20)\n",
    "c = a.logical_and(b) # 요소별 논리 AND\n",
    "print(c)\n",
    "c = a.logical_or(b)  # 요소별 논리 OR\n",
    "print(c)\n",
    "c = c.logical_not()  # 요소별 논리 NOT  \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "379d0fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9742,  0.1250,  1.2679],\n",
      "        [ 0.4075,  0.6993, -0.9395]])\n",
      "tensor([ 0.9742,  0.1250,  1.2679,  0.4075,  0.6993, -0.9395])\n",
      "tensor([[ 0.9742,  0.1250],\n",
      "        [ 1.2679,  0.4075],\n",
      "        [ 0.6993, -0.9395]])\n",
      "tensor([[ 0.9742,  0.4075],\n",
      "        [ 0.1250,  0.6993],\n",
      "        [ 1.2679, -0.9395]])\n",
      "tensor([[ 0.9742,  0.4075],\n",
      "        [ 0.1250,  0.6993],\n",
      "        [ 1.2679, -0.9395]])\n",
      "tensor([[[ 0.9742,  0.1250,  1.2679],\n",
      "         [ 0.4075,  0.6993, -0.9395]]])\n",
      "tensor([[[ 0.9742,  0.1250,  1.2679]],\n",
      "\n",
      "        [[ 0.4075,  0.6993, -0.9395]]])\n",
      "tensor([[[ 0.9742],\n",
      "         [ 0.1250],\n",
      "         [ 1.2679]],\n",
      "\n",
      "        [[ 0.4075],\n",
      "         [ 0.6993],\n",
      "         [-0.9395]]])\n",
      "tensor([[ 0.9742,  0.1250,  1.2679],\n",
      "        [ 0.4075,  0.6993, -0.9395]])\n",
      "tensor([[ 0.9742,  0.1250,  1.2679],\n",
      "        [ 0.4075,  0.6993, -0.9395]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 변형 함수\n",
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "\n",
    "print(torch.flatten(a))      # 다차원 텐서를 1-D tensor로 변환\n",
    "print(torch.reshape(a, (3,2))) # 텐서의 shape 변경\n",
    "print(torch.transpose(a, 0, 1)) # 텐서의 차원 교환\n",
    "print(torch.t(a))            # 2-D tensor의 전치행렬\n",
    "print(torch.unsqueeze(a, 0)) # 지정한 위치에 차원 추가\n",
    "print(torch.unsqueeze(a, 1)) # 지정한 위치에 차원 추가\n",
    "print(torch.unsqueeze(a, 2)) # 지정한 위치에 차원 추가\n",
    "print(torch.squeeze(a))      # 크기가 1인 차원 제거\n",
    "print(torch.squeeze(torch.unsqueeze(a, 0))) # 크기가 1인 차원 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ba9632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 8, 6],\n",
      "        [0, 8, 8]])\n",
      "--------------------\n",
      "tensor([[7, 8, 6],\n",
      "        [0, 8, 8],\n",
      "        [7, 8, 6],\n",
      "        [0, 8, 8]])\n",
      "torch.Size([4, 3])\n",
      "--------------------\n",
      "tensor([[7, 8, 6, 7, 8, 6],\n",
      "        [0, 8, 8, 0, 8, 8]])\n",
      "torch.Size([2, 6])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 텐서 결합 함수 cat\n",
    "\n",
    "a = torch.randint(9, (2, 3))\n",
    "print(a)\n",
    "\n",
    "print(\"-\"*20)\n",
    "b = torch.cat([a, a], dim=0)  # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)\n",
    "b = torch.cat([a, a], dim=1) # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13e5572f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 7, 6, 8],\n",
      "        [0, 7, 0, 3],\n",
      "        [3, 2, 6, 0]])\n",
      "torch.Size([3, 4])\n",
      "--------------------\n",
      "tensor([[[3, 7, 6, 8],\n",
      "         [0, 7, 0, 3],\n",
      "         [3, 2, 6, 0]],\n",
      "\n",
      "        [[3, 7, 6, 8],\n",
      "         [0, 7, 0, 3],\n",
      "         [3, 2, 6, 0]]])\n",
      "torch.Size([2, 3, 4])\n",
      "--------------------\n",
      "tensor([[[3, 7, 6, 8],\n",
      "         [3, 7, 6, 8]],\n",
      "\n",
      "        [[0, 7, 0, 3],\n",
      "         [0, 7, 0, 3]],\n",
      "\n",
      "        [[3, 2, 6, 0],\n",
      "         [3, 2, 6, 0]]])\n",
      "torch.Size([3, 2, 4])\n",
      "--------------------\n",
      "tensor([[[3, 3],\n",
      "         [7, 7],\n",
      "         [6, 6],\n",
      "         [8, 8]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [7, 7],\n",
      "         [0, 0],\n",
      "         [3, 3]],\n",
      "\n",
      "        [[3, 3],\n",
      "         [2, 2],\n",
      "         [6, 6],\n",
      "         [0, 0]]])\n",
      "torch.Size([3, 4, 2])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 텐서 결합 함수 stack\n",
    "a = torch.randint(9, (3,4))\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(\"-\"*20)\n",
    "b = torch.stack([a, a], dim=0) # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)\n",
    "b = torch.stack([a, a], dim=1) # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)\n",
    "b = torch.stack([a, a], dim=2) # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10afebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5000])\n",
      "3.5\n",
      "torch.Size([1])\n",
      "1\n",
      "torch.float32\n",
      "1\n",
      "False\n",
      "tensor([False])\n"
     ]
    }
   ],
   "source": [
    "# tensor가 아닌 Python 기본 타입을 출력하는 경우\n",
    "a = torch.tensor([3.5])\n",
    "print(a)\n",
    "print(a.item())  # 스칼라 텐서의 값을 Python 기본 타입으로 반환 \n",
    "\n",
    "#크기/차원 정보\n",
    "print(a.shape) # torch.Size([1])\n",
    "print(a.ndim)  # 1\n",
    "print(a.dtype) # torch.float32  \n",
    "print(a.numel()) # 1, 텐서의 모든 요소 개수\n",
    "\n",
    "# 전체 동등성 검사\n",
    "b = torch.tensor([2.5])\n",
    "print(a.equal(b))  # False\n",
    "print(a == b)      # tensor([False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e7c5de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 8, 2],\n",
      "        [7, 0, 1]])\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 일부 검사함수\n",
    "a = torch.randint(9, (2, 3))\n",
    "print(a)   \n",
    "b = a.is_floating_point() # 실수형 여부\n",
    "print(b)\n",
    "b = a.is_complex()       # 복소수형 여부\n",
    "print(b)\n",
    "b = a.is_same_size(a)    # 동일한 shape인지 여부\n",
    "print(b)    \n",
    "b = a.is_contiguous()    # 메모리상에 연속적으로 저장되어 있는지 여부\n",
    "print(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d22e4eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6001, 0.4721, 0.9981],\n",
      "        [0.1062, 0.0771, 0.6550]])\n",
      "tensor([0.6094, 0.4784, 1.1938])\n",
      "tensor([1.2567, 0.6680])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((2, 3))\n",
    "print(a)\n",
    "\n",
    "b = a.norm(p=2, dim=0) # 열벡터의 L2 norm 계산\n",
    "print(b)\n",
    "b = a.norm(p=2, dim=1) # 행벡터의 L2 norm 계산\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "658658d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = torch.randn(5, 3).numpy() # 5개의 샘플과 3개의 특성\n",
    "y = torch.randn(5).numpy()    # 5개의 샘플에 대한 타겟 값\n",
    "\n",
    "# X에 적용할 scaler 객체 생성\n",
    "scaler = StandardScaler().fit(X)\n",
    "# y에 적용할 scaler 객체 생성\n",
    "scaler_y = StandardScaler().fit(y.reshape(-1, 1))\n",
    "# X에 transform 적용\n",
    "X_scaled = scaler.transform(X)\n",
    "# y에 transform 적용\n",
    "y_scaled = scaler_y.transform(y.reshape(-1, 1)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceed9ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9652, 0.1775, 0.4340],\n",
      "        [0.4004, 0.9515, 0.5338]])\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 1.]]\n",
      "tensor([[0.7945, 0.4032, 0.8754],\n",
      "        [0.2081, 0.1681, 0.5706]])\n",
      "[[0.6360772  0.32276872 0.7008753 ]\n",
      " [0.33024856 0.26670748 0.9054297 ]]\n",
      "tensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "a = torch.rand((2,3))\n",
    "print(a)\n",
    "b = mm.fit_transform(a)\n",
    "print(b)\n",
    "\n",
    "norm = Normalizer(norm='l2')\n",
    "a = torch.rand((2,3))\n",
    "print(a)\n",
    "b = norm.fit_transform(a)\n",
    "print(b)\n",
    "print(torch.norm(torch.tensor(b), p=2, dim=1))  # 행벡터의 L2 norm 계산, 모두 1.0이 나옴\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3ec684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6898,  0.6810,  0.4189, -0.4413,  0.1932],\n",
      "        [-0.4704, -0.1546, -0.2401,  1.3012,  0.3067],\n",
      "        [ 0.2017,  0.4894,  0.1515, -0.3606, -1.1360]])\n",
      "tensor([[-0.4609,  0.5594,  0.2620, -0.4065, -0.1208],\n",
      "        [-0.7889, -0.7115,  0.7230, -0.3857, -0.5172],\n",
      "        [-0.3409,  0.2743, -0.0330, -0.7731,  0.3041]])\n",
      "tensor([[-0.9444, -0.4362, -0.5706, -0.4035, -0.4431],\n",
      "        [ 0.9654, -0.0454,  1.2910, -0.2830, -0.8608],\n",
      "        [-1.3790,  0.7629, -0.8594,  0.0178,  0.3878]])\n",
      "tensor([[-0.6204,  0.1156, -0.8824, -0.8385, -0.5180],\n",
      "        [-0.7299,  0.0025,  0.4165, -0.4534,  0.6242],\n",
      "        [ 0.0420, -0.8638, -0.2323,  0.9321, -0.8336]])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "weight = torch.empty(3, 5)\n",
    "\n",
    "# sigmoid\n",
    "nn.init.xavier_normal_(weight)\n",
    "print(weight)\n",
    "nn.init.xavier_uniform_(weight)\n",
    "print(weight)\n",
    "\n",
    "# ReLU\n",
    "nn.init.kaiming_normal_(weight, mode='fan_in', nonlinearity='relu')\n",
    "print(weight)\n",
    "nn.init.kaiming_uniform_(weight, mode='fan_in', nonlinearity='relu')\n",
    "print(weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boostcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
