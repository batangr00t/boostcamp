{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fae2111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90eb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "torch.Size([])\n",
      "0\n",
      "torch.int64\n",
      "tensor(-3.8736)\n",
      "torch.Size([])\n",
      "0\n",
      "torch.float32\n",
      "tensor([[[0.6464, 0.2190, 0.3491, 0.1715, 0.6927],\n",
      "         [0.5851, 0.8262, 0.7804, 0.0249, 0.2472],\n",
      "         [0.7990, 0.6928, 0.7007, 0.9647, 0.5964],\n",
      "         [0.3987, 0.9602, 0.1992, 0.3600, 0.0203]],\n",
      "\n",
      "        [[0.9545, 0.3374, 0.1573, 0.5573, 0.6754],\n",
      "         [0.3582, 0.1536, 0.7443, 0.3852, 0.6371],\n",
      "         [0.0181, 0.8723, 0.5822, 0.3664, 0.6135],\n",
      "         [0.0846, 0.2743, 0.4268, 0.8712, 0.1239]],\n",
      "\n",
      "        [[0.0787, 0.8582, 0.8458, 0.6987, 0.9896],\n",
      "         [0.4355, 0.4469, 0.0590, 0.6033, 0.0257],\n",
      "         [0.4188, 0.2952, 0.4162, 0.6849, 0.6183],\n",
      "         [0.0276, 0.8214, 0.0886, 0.9776, 0.7972]]])\n",
      "tensor(4.4621)\n",
      "torch.Size([])\n",
      "0\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 0-D tensor\n",
    "scalar = torch.tensor(3)   \n",
    "print(scalar)       # tensor(3)\n",
    "print(scalar.shape) # torch.Size([])\n",
    "print(scalar.ndim)  # 0\n",
    "print(scalar.dtype) # torch.int64\n",
    "\n",
    "scalar2 = torch.randn(10).sum()\n",
    "print(scalar2)       # tensor(-0.6778)\n",
    "print(scalar2.shape) # torch.Size([])\n",
    "print(scalar2.ndim)  # 0\n",
    "print(scalar2.dtype) # torch.float32\n",
    "\n",
    "a = torch.rand((3,4,5))\n",
    "print(a)\n",
    "scalar3 = torch.norm(a)\n",
    "print(scalar3)       # tensor(4.4621)\n",
    "print(scalar3.shape) # torch.Size([])\n",
    "print(scalar3.ndim)  # 0\n",
    "print(scalar3.dtype) # torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea85bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "torch.Size([3])\n",
      "1\n",
      "torch.int64\n",
      "tensor([4])\n",
      "torch.Size([1])\n",
      "1\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# 1-D tensor\n",
    "vector1 = torch.tensor([1,2,3]) # 0-D tensor가 1,2,3 인 배열\n",
    "print(vector1)       # tensor([1, 2, 3])\n",
    "print(vector1.shape) # torch.Size([3])\n",
    "print(vector1.ndim)  # 1\n",
    "print(vector1.dtype) # torch.int64\n",
    "\n",
    "vector2 = torch.randint(5, [1]) # 0-D tensor가 1개인 배열\n",
    "print(vector2)       # tensor([3]), 0-D 텐서인 tensor(3)과 다름\n",
    "print(vector2.shape) # torch.Size([1])\n",
    "print(vector2.ndim)  # 1\n",
    "print(vector2.dtype) # torch.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce3cac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "torch.Size([3, 4])\n",
      "2\n",
      "torch.float32\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]], dtype=torch.float64)\n",
      "torch.Size([4, 4])\n",
      "2\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# 2-D tensor\n",
    "matrix1 = torch.zeros(3, 4) # 1-D tensor가 3개인 배열\n",
    "print(matrix1)\n",
    "print(matrix1.size()) # torch.Size([3, 4])\n",
    "print(matrix1.dim())  # 2\n",
    "print(matrix1.dtype)  # torch.float32\n",
    "\n",
    "matrix2 = torch.eye(4, dtype=torch.double)  # 1-D tensor가 4개인 배열\n",
    "print(matrix2)\n",
    "print(matrix2.size()) # torch.Size([4, 4])\n",
    "print(matrix2.dim())  # 2\n",
    "print(matrix2.dtype)  # torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3d11739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4, 3, 4, 3],\n",
      "         [5, 0, 1, 3],\n",
      "         [3, 6, 8, 6]],\n",
      "\n",
      "        [[5, 3, 2, 1],\n",
      "         [1, 5, 0, 4],\n",
      "         [2, 0, 1, 6]]])\n",
      "tensor(76)\n",
      "tensor([[ 9,  6,  6,  4],\n",
      "        [ 6,  5,  1,  7],\n",
      "        [ 5,  6,  9, 12]])\n",
      "tensor([[12,  9, 13, 12],\n",
      "        [ 8,  8,  3, 11]])\n",
      "tensor([[14,  9, 23],\n",
      "        [11, 10,  9]])\n",
      "tensor([[14,  9, 23],\n",
      "        [11, 10,  9]])\n",
      "tensor([[12,  9, 13, 12],\n",
      "        [ 8,  8,  3, 11]])\n",
      "tensor([[ 9,  6,  6,  4],\n",
      "        [ 6,  5,  1,  7],\n",
      "        [ 5,  6,  9, 12]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(10, (2,3,4))\n",
    "print(a)\n",
    "\n",
    "# 전체 element 더하여 스칼라 텐서 생성됨, 결과는 0-D tensor\n",
    "result = a.sum()\n",
    "print(result)\n",
    "\n",
    "# dim-0차원 2개의 배열을 더함, 스칼라 탠서로 변하면서 차원이 사라짐 => 결과는 (3,4) shape의 탠서\n",
    "result = a.sum(dim=0)\n",
    "print(result)\n",
    "\n",
    "# dim-1차원 3개의 배열을 더함, 스칼라 텐서로 변하면서 해당 차원이 사라짐 => 결과는 (2,4) shape의 탠서\n",
    "result = a.sum(dim=1)\n",
    "print(result)\n",
    "\n",
    "# dim-2차원 4개의 배열을 더함, 스칼라 텐서로 변하면서 해당 차원이 사라짐 => 결과는 (2,3) shape의 탠서\n",
    "result = a.sum(dim=2)\n",
    "print(result)\n",
    "\n",
    "result = a.sum(dim=-1)\n",
    "print(result)\n",
    "result = a.sum(dim=-2)\n",
    "print(result)\n",
    "result = a.sum(dim=-3)\n",
    "print(result)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a738111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3650,  0.9625, -1.2006],\n",
      "        [-0.3323, -1.2849,  1.1461]])\n",
      "tensor([[-0.7497, -1.4571,  0.6495],\n",
      "        [-1.5047, -0.9088, -0.8864]])\n",
      "tensor([[-1.1147, -0.4946, -0.5511],\n",
      "        [-1.8370, -2.1937,  0.2597]])\n",
      "tensor([[-1.1147, -0.4946, -0.5511],\n",
      "        [-1.8370, -2.1937,  0.2597]])\n",
      "tensor([[ 0.3848,  2.4196, -1.8501],\n",
      "        [ 1.1724, -0.3761,  2.0325]])\n",
      "tensor([[ 0.3848,  2.4196, -1.8501],\n",
      "        [ 1.1724, -0.3761,  2.0325]])\n",
      "tensor([[ 0.2736, -1.4025, -0.7798],\n",
      "        [ 0.5000,  1.1677, -1.0159]])\n",
      "tensor([[ 0.2736, -1.4025, -0.7798],\n",
      "        [ 0.5000,  1.1677, -1.0159]])\n",
      "tensor([[ 0.4868, -0.6605, -1.8485],\n",
      "        [ 0.2208,  1.4138, -1.2930]])\n",
      "tensor([[ 0.4868, -0.6605, -1.8485],\n",
      "        [ 0.2208,  1.4138, -1.2930]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "b = torch.randn(2, 3)\n",
    "print(b)\n",
    "# 2-D tensor + 2-D tensor\n",
    "print(a + b)\n",
    "print(torch.add(a, b))\n",
    "# 2-D tensor - 2-D tensor\n",
    "print(a - b)\n",
    "print(torch.sub(a, b))\n",
    "# 2-D tensor * 2-D tensor\n",
    "print(a * b)\n",
    "print(torch.mul(a, b))\n",
    "# 2-D tensor / 2-D tensor\n",
    "print(a / b)\n",
    "print(torch.div(a, b))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c922b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3465, -0.0053, -0.3504],\n",
      "        [-1.0029, -1.8632, -1.8125]])\n",
      "tensor([[ 1.1456,  1.3126,  1.2783, -0.5436],\n",
      "        [-1.2600, -0.0510,  0.4871, -0.6189],\n",
      "        [-0.0483, -1.5231, -0.7121, -1.5880]])\n",
      "tensor([[-0.3734,  0.0792, -0.1960,  0.7481],\n",
      "        [ 1.2864,  1.5395, -0.8988,  4.5766]])\n",
      "tensor([[-0.3734,  0.0792, -0.1960,  0.7481],\n",
      "        [ 1.2864,  1.5395, -0.8988,  4.5766]])\n",
      "tensor([[-0.3734,  0.0792, -0.1960,  0.7481],\n",
      "        [ 1.2864,  1.5395, -0.8988,  4.5766]])\n",
      "tensor([[-0.3734,  0.0792, -0.1960,  0.7481],\n",
      "        [ 1.2864,  1.5395, -0.8988,  4.5766]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 행렬곱\n",
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "b = torch.randn(3, 4)\n",
    "print(b)\n",
    "# 2-D tensor @ 2-D tensor\n",
    "print(a @ b)\n",
    "print(torch.matmul(a, b))\n",
    "# 2-D tensor . 2-D tensor\n",
    "print(a.mm(b))\n",
    "print(torch.mm(a, b))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5e9881b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6627,  2.4958,  3.0296],\n",
      "        [-0.5729, -0.0777, -0.3991]])\n",
      "tensor([[0.6627, 2.4958, 3.0296],\n",
      "        [0.5729, 0.0777, 0.3991]])\n",
      "tensor([[2.2952,    nan,    nan],\n",
      "        [2.1808, 1.6486, 1.9813]])\n",
      "tensor([[-0.7244,     nan,     nan],\n",
      "        [-0.6101, -0.0778, -0.4105]])\n",
      "tensor([[-0.5852,  1.1897,  1.2520],\n",
      "        [-0.5203, -0.0776, -0.3797]])\n",
      "tensor([[-0., 3., 4.],\n",
      "        [-0., -0., -0.]])\n",
      "tensor([[0.0000, 2.4958, 3.0296],\n",
      "        [0.0000, 0.0000, 0.0000]])\n",
      "tensor([[ 0.7883, -0.7987, -0.9937],\n",
      "        [ 0.8403,  0.9970,  0.9214]])\n",
      "tensor([[ 1.2277,  6.1072, 10.3687],\n",
      "        [ 1.1687,  1.0030,  1.0807]])\n",
      "tensor([[ 0.5155, 12.1320, 20.6890],\n",
      "        [ 0.5639,  0.9252,  0.6709]])\n",
      "tensor([[-1.,  2.,  3.],\n",
      "        [-1., -1., -1.]])\n",
      "tensor([[   nan, 0.9146, 1.1084],\n",
      "        [   nan,    nan,    nan]])\n",
      "tensor([[   nan, 0.3972, 0.4814],\n",
      "        [   nan,    nan,    nan]])\n",
      "tensor([[   nan, 1.3195, 1.5991],\n",
      "        [   nan,    nan,    nan]])\n",
      "tensor([[ 0.6627, -2.4958, -3.0296],\n",
      "        [ 0.5729,  0.0777,  0.3991]])\n",
      "tensor([[ -1.5090,   0.4007,   0.3301],\n",
      "        [ -1.7455, -12.8624,  -2.5056]])\n",
      "tensor([[-1.,  2.,  3.],\n",
      "        [-1., -0., -0.]])\n",
      "tensor([[   nan, 0.6330, 0.5745],\n",
      "        [   nan,    nan,    nan]])\n",
      "tensor([[-1.,  1.,  1.],\n",
      "        [-1., -1., -1.]])\n",
      "tensor([[-0.6152,  0.6018,  0.1118],\n",
      "        [-0.5421, -0.0777, -0.3886]])\n",
      "tensor([[-0.7123,  6.0248, 10.3203],\n",
      "        [-0.6048, -0.0778, -0.4098]])\n",
      "tensor([[   nan, 1.5798, 1.7406],\n",
      "        [   nan,    nan,    nan]])\n",
      "tensor([[-0.7804, -0.7535, -0.1125],\n",
      "        [-0.6451, -0.0779, -0.4217]])\n",
      "tensor([[-0.5801,  0.9865,  0.9953],\n",
      "        [-0.5175, -0.0776, -0.3792]])\n",
      "tensor([[-0., 2., 3.],\n",
      "        [-0., -0., -0.]])\n",
      "tensor([[False, False, False],\n",
      "        [False, False, False]])\n",
      "tensor([[False,  True,  True],\n",
      "        [False, False, False]])\n",
      "tensor([[False,  True,  True],\n",
      "        [False, False, False]])\n",
      "tensor([[ True, False, False],\n",
      "        [ True,  True,  True]])\n",
      "tensor([[ True, False, False],\n",
      "        [ True,  True,  True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(3.0296)\n",
      "tensor(-0.6627)\n",
      "tensor(0.6355)\n",
      "tensor(-0.3991)\n",
      "torch.return_types.mode(\n",
      "values=tensor([-0.6627, -0.5729]),\n",
      "indices=tensor([0, 0]))\n",
      "tensor(1.6684)\n",
      "tensor(2.7835)\n",
      "tensor(3.8130)\n",
      "tensor(0.0891)\n",
      "tensor([[-0.6627,  2.4958,  3.0296],\n",
      "        [-1.2356,  2.4181,  2.6305]])\n",
      "tensor([[-0.6627,  2.4958,  3.0296],\n",
      "        [ 0.3797, -0.1940, -1.2091]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[-0.6627, -0.0777, -0.3991],\n",
      "        [-0.5729,  2.4958,  3.0296]]),\n",
      "indices=tensor([[0, 1, 1],\n",
      "        [1, 0, 0]]))\n",
      "tensor([[0, 1, 1],\n",
      "        [1, 0, 0]])\n",
      "tensor([-0.6627, -0.5729, -0.3991, -0.0777,  2.4958,  3.0296])\n",
      "tensor([[0.6627, 2.4958, 3.0296],\n",
      "        [0.5729, 0.0777, 0.3991]])\n",
      "tensor([[0, 0],\n",
      "        [0, 1],\n",
      "        [0, 2],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [1, 2]])\n"
     ]
    }
   ],
   "source": [
    "# 공용함수, 삼각함수, 지수함수, 로그함수, 비교함수, 논리함수, 통계함수, 선형대수 함수 등\n",
    "a = torch.randn(2, 3)\n",
    "print(a)    \n",
    "print(torch.abs(a))        # 절댓값\n",
    "print(torch.acos(a))       # 아크코사인\n",
    "print(torch.asin(a))       # 아크사인\n",
    "print(torch.atan(a))       # 아크탄젠트\n",
    "print(torch.ceil(a))       # 올림\n",
    "print(torch.clamp(a, min=0.0)) # 최소값 지정\n",
    "print(torch.cos(a))        # 코사인\n",
    "print(torch.cosh(a))       # 쌍곡코사인\n",
    "print(torch.exp(a))        # 지수함수\n",
    "print(torch.floor(a))      # 내림\n",
    "print(torch.log(a))        # 자연로그\n",
    "print(torch.log10(a))      # 상용로그\n",
    "print(torch.log2(a))       # 이진로그\n",
    "print(torch.neg(a))        # 음수\n",
    "print(torch.reciprocal(a)) # 역수\n",
    "print(torch.round(a))      # 반올림\n",
    "print(torch.rsqrt(a))      # 역수의 제곱근\n",
    "print(torch.sign(a))       # 부호\n",
    "print(torch.sin(a))        # 사인\n",
    "print(torch.sinh(a))       # 쌍곡사인\n",
    "print(torch.sqrt(a))       # 제곱근\n",
    "print(torch.tan(a))        # 탄젠트\n",
    "print(torch.tanh(a))       # 쌍곡탄젠트\n",
    "print(torch.trunc(a))      # 정수부분\n",
    "print(torch.eq(a, 0.0))    # 요소별 동일여부\n",
    "print(torch.ge(a, 0.0))    # 요소별 크거나 같은지 여부\n",
    "print(torch.gt(a, 0.0))    # 요소별 큰지 여부\n",
    "print(torch.le(a, 0.0))    # 요소별 작거나 같은지 여부\n",
    "print(torch.lt(a, 0.0))    # 요소별 작은지 여부\n",
    "print(torch.ne(a, 0.0))    # 요소별 같지 않은지 여부\n",
    "print(torch.all(a))        # 모든 요소가 참인지 여부\n",
    "print(torch.any(a))        # 하나 이상의 요소가 참인지 여부\n",
    "print(torch.argmax(a))     # 가장 큰 요소의 인덱스\n",
    "print(torch.argmin(a))     # 가장 작은 요소의 인덱스\n",
    "print(torch.max(a))        # 가장 큰 요소\n",
    "print(torch.min(a))        # 가장 작은 요소\n",
    "print(torch.mean(a))       # 평균\n",
    "print(torch.median(a))     # 중앙값\n",
    "print(torch.mode(a))       # 최빈값\n",
    "print(torch.std(a))        # 표준편차\n",
    "print(torch.var(a))        # 분산\n",
    "print(torch.sum(a))        # 합 \n",
    "print(torch.prod(a))       # 곱\n",
    "print(torch.cumsum(a, dim=0)) # 누적합\n",
    "print(torch.cumprod(a, dim=0))# 누적곱\n",
    "print(torch.sort(a, dim=0))   # 정렬\n",
    "print(torch.argsort(a, dim=0))# 정렬된 인덱스\n",
    "print(torch.unique(a))        # 중복제거\n",
    "print(torch.where(a>0, a, -a))# 조건에 따라 값 선택\n",
    "print(torch.nonzero(a))      # 0이 아닌 요소의 인덱스\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0166aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "tensor([[ True,  True,  True],\n",
      "        [False,  True,  True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[False, False, False],\n",
      "        [False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(9, (2, 3))\n",
    "b = torch.randint(9, (2, 3))\n",
    "print(\"-\"*20)\n",
    "c = a.logical_and(b) # 요소별 논리 AND\n",
    "print(c)\n",
    "c = a.logical_or(b)  # 요소별 논리 OR\n",
    "print(c)\n",
    "c = c.logical_not()  # 요소별 논리 NOT  \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d0fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5821,  0.0827, -1.6979],\n",
      "        [-1.4800,  0.0581, -0.3157]])\n",
      "tensor([-1.5821,  0.0827, -1.6979, -1.4800,  0.0581, -0.3157])\n",
      "tensor([[-1.5821,  0.0827],\n",
      "        [-1.6979, -1.4800],\n",
      "        [ 0.0581, -0.3157]])\n",
      "tensor([[-1.5821, -1.4800],\n",
      "        [ 0.0827,  0.0581],\n",
      "        [-1.6979, -0.3157]])\n",
      "tensor([[-1.5821, -1.4800],\n",
      "        [ 0.0827,  0.0581],\n",
      "        [-1.6979, -0.3157]])\n",
      "tensor([[[-1.5821,  0.0827, -1.6979],\n",
      "         [-1.4800,  0.0581, -0.3157]]])\n",
      "tensor([[[-1.5821,  0.0827, -1.6979]],\n",
      "\n",
      "        [[-1.4800,  0.0581, -0.3157]]])\n",
      "tensor([[[-1.5821],\n",
      "         [ 0.0827],\n",
      "         [-1.6979]],\n",
      "\n",
      "        [[-1.4800],\n",
      "         [ 0.0581],\n",
      "         [-0.3157]]])\n",
      "tensor([[-1.5821,  0.0827, -1.6979],\n",
      "        [-1.4800,  0.0581, -0.3157]])\n",
      "tensor([[-1.5821,  0.0827, -1.6979],\n",
      "        [-1.4800,  0.0581, -0.3157]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 변형 함수\n",
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "\n",
    "print(torch.flatten(a))      # 다차원 텐서를 1-D tensor로 변환\n",
    "print(torch.reshape(a, (3,2))) # 텐서의 shape 변경\n",
    "print(torch.transpose(a, 0, 1)) # 텐서의 차원 교환\n",
    "print(torch.t(a))            # 2-D tensor의 전치행렬\n",
    "print(torch.unsqueeze(a, 0)) # 지정한 위치에 차원 추가\n",
    "print(torch.unsqueeze(a, 1)) # 지정한 위치에 차원 추가\n",
    "print(torch.unsqueeze(a, 2)) # 지정한 위치에 차원 추가\n",
    "print(torch.squeeze(a))      # 크기가 1인 차원 제거\n",
    "print(torch.squeeze(torch.unsqueeze(a, 0))) # 크기가 1인 차원 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba9632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 4, 6],\n",
      "        [1, 2, 2]])\n",
      "--------------------\n",
      "tensor([[0, 4, 6],\n",
      "        [1, 2, 2],\n",
      "        [0, 4, 6],\n",
      "        [1, 2, 2]])\n",
      "torch.Size([4, 3])\n",
      "--------------------\n",
      "tensor([[0, 4, 6, 0, 4, 6],\n",
      "        [1, 2, 2, 1, 2, 2]])\n",
      "torch.Size([2, 6])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 텐서 결합 함수 cat\n",
    "\n",
    "a = torch.randint(9, (2, 3))\n",
    "print(a)\n",
    "\n",
    "print(\"-\"*20)\n",
    "b = torch.cat([a, a], dim=0)  # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)\n",
    "b = torch.cat([a, a], dim=1) # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e5572f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3, 7, 2],\n",
      "        [4, 8, 6, 2],\n",
      "        [7, 2, 1, 4]])\n",
      "torch.Size([3, 4])\n",
      "--------------------\n",
      "tensor([[[2, 3, 7, 2],\n",
      "         [4, 8, 6, 2],\n",
      "         [7, 2, 1, 4]],\n",
      "\n",
      "        [[2, 3, 7, 2],\n",
      "         [4, 8, 6, 2],\n",
      "         [7, 2, 1, 4]]])\n",
      "torch.Size([2, 3, 4])\n",
      "--------------------\n",
      "tensor([[[2, 3, 7, 2],\n",
      "         [2, 3, 7, 2]],\n",
      "\n",
      "        [[4, 8, 6, 2],\n",
      "         [4, 8, 6, 2]],\n",
      "\n",
      "        [[7, 2, 1, 4],\n",
      "         [7, 2, 1, 4]]])\n",
      "torch.Size([3, 2, 4])\n",
      "--------------------\n",
      "tensor([[[2, 2],\n",
      "         [3, 3],\n",
      "         [7, 7],\n",
      "         [2, 2]],\n",
      "\n",
      "        [[4, 4],\n",
      "         [8, 8],\n",
      "         [6, 6],\n",
      "         [2, 2]],\n",
      "\n",
      "        [[7, 7],\n",
      "         [2, 2],\n",
      "         [1, 1],\n",
      "         [4, 4]]])\n",
      "torch.Size([3, 4, 2])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 텐서 결합 함수 stack\n",
    "a = torch.randint(9, (3,4))\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(\"-\"*20)\n",
    "b = torch.stack([a, a], dim=0) # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)\n",
    "b = torch.stack([a, a], dim=1) # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)\n",
    "b = torch.stack([a, a], dim=2) # 지정한 차원의 크기를 증가시킴\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10afebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5000])\n",
      "3.5\n",
      "torch.Size([1])\n",
      "1\n",
      "torch.float32\n",
      "1\n",
      "False\n",
      "tensor([False])\n"
     ]
    }
   ],
   "source": [
    "# tensor가 아닌 Python 기본 타입을 출력하는 경우\n",
    "a = torch.tensor([3.5])\n",
    "print(a)\n",
    "print(a.item())  # 스칼라 텐서의 값을 Python 기본 타입으로 반환 \n",
    "\n",
    "#크기/차원 정보\n",
    "print(a.shape) # torch.Size([1])\n",
    "print(a.ndim)  # 1\n",
    "print(a.dtype) # torch.float32  \n",
    "print(a.numel()) # 1, 텐서의 모든 요소 개수\n",
    "\n",
    "# 전체 동등성 검사\n",
    "b = torch.tensor([2.5])\n",
    "print(a.equal(b))  # False\n",
    "print(a == b)      # tensor([False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e7c5de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8, 7, 8],\n",
      "        [3, 5, 8]])\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 일부 검사함수\n",
    "a = torch.randint(9, (2, 3))\n",
    "print(a)   \n",
    "b = a.is_floating_point() # 실수형 여부\n",
    "print(b)\n",
    "b = a.is_complex()       # 복소수형 여부\n",
    "print(b)\n",
    "b = a.is_same_size(a)    # 동일한 shape인지 여부\n",
    "print(b)    \n",
    "b = a.is_contiguous()    # 메모리상에 연속적으로 저장되어 있는지 여부\n",
    "print(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d22e4eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8597, 0.4340, 0.8291],\n",
      "        [0.2461, 0.3508, 0.7779]])\n",
      "tensor([0.8943, 0.5581, 1.1369])\n",
      "tensor([1.2708, 0.8881])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((2, 3))\n",
    "print(a)\n",
    "\n",
    "b = a.norm(p=2, dim=0) # 열벡터의 L2 norm 계산\n",
    "print(b)\n",
    "b = a.norm(p=2, dim=1) # 행벡터의 L2 norm 계산\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658658d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.19453548 -1.4225612  -0.35592303]\n",
      " [ 1.2291666   0.85571223  1.7130218 ]\n",
      " [ 0.8321378   0.37036565  0.13470927]\n",
      " [-1.6462796  -0.92342424 -0.1103007 ]\n",
      " [-0.2204894   1.1199076  -1.3815073 ]]\n",
      "[[ 0.74191433]\n",
      " [ 0.5432975 ]\n",
      " [-1.7916003 ]\n",
      " [ 0.8920779 ]\n",
      " [-0.38568944]]\n",
      "(5, 3)\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = torch.randn(5, 3).numpy() # 5개의 샘플과 3개의 특성\n",
    "y = torch.randn(5).numpy()    # 5개의 샘플에 대한 타겟 값\n",
    "\n",
    "# X에 적용할 scaler 객체 생성\n",
    "scaler = StandardScaler().fit(X)\n",
    "# y에 적용할 scaler 객체 생성\n",
    "scaler_y = StandardScaler().fit(y.reshape(-1, 1))\n",
    "# X에 transform 적용\n",
    "X_scaled = scaler.transform(X)\n",
    "# y에 transform 적용\n",
    "y_scaled = scaler_y.transform(y.reshape(-1, 1)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ceed9ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1342, 0.2758, 0.0850],\n",
      "        [0.7979, 0.9123, 0.5614]])\n",
      "[[0. 0. 0.]\n",
      " [1. 1. 1.]]\n",
      "tensor([[0.4099, 0.1707, 0.4768],\n",
      "        [0.3294, 0.6081, 0.0331]])\n",
      "[[0.629098   0.26206008 0.73181987]\n",
      " [0.47580564 0.8782536  0.0477452 ]]\n",
      "tensor([1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "a = torch.rand((2,3))\n",
    "print(a)\n",
    "b = mm.fit_transform(a)\n",
    "print(b)\n",
    "\n",
    "norm = Normalizer(norm='l2')\n",
    "a = torch.rand((2,3))\n",
    "print(a)\n",
    "b = norm.fit_transform(a)\n",
    "print(b)\n",
    "print(torch.norm(torch.tensor(b), p=2, dim=1))  # 행벡터의 L2 norm 계산, 모두 1.0이 나옴\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boostcamp (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
